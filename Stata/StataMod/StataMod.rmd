
```{r, echo=FALSE, message=FALSE}
require(knitr)
statapath <- "C:/Program Files/Stata16/StataMP-64.exe"
opts_chunk$set(collectcode = TRUE, echo = FALSE, cleanlog = FALSE, engine="stata", engine.path=list(stata=statapath), comment="")
```


# Stata Modeling 

**Topics**

* Stata modeling
    + Multiple regression
    + Testing model assumptions
    + Interactions
    + Exporting regression tables
* Obtaining margins of responses 
    + margins of logistic regression 
    + margins of OLS regression 
* Different types of adjusted predictions and marginal effects 
    + APM: adjusted predictions at the mean 
    + MEM: marginal effects at the mean
    + AAP: average adjusted predictions
    + AME: average marginal effects
    + APR: adjusted predictions at representative values 
    + MER: marginal effects at representative values
    
  
## Setup

### Class Structure and organization 

* Informal --- Ask questions at any time. Really!
* Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!
* If you are using a laptop, you will need to adjust file paths accordingly
* Make comments in your Do-file - save on flash drive or email to yourself


### Prerequisites

This is an intermediate-level Stata modeling workshop 

* Assumes basic knowledge of Stata
* Not appropriate for people already well familiar with modeling in Stata
* If you are catching on before the rest of the class, experiment with command features described in help files


## Goals

<div class="alert alert-success">
**We will learn about the Stata language by analyzing data from several datasets.** In particular, our goals are:

1. Fit models in Stata 
2. Test modeling assumptions
3. Learn how to obtain marginal effects 
4. Obtain margins with interaction terms 
5. Distinguish and choose from different types of margins  
</div>


## Multiple regression

<div class="alert alert-info">
**GOAL: To learn the basics about modeling in Stata, test model assumptions, how to add interaction terms and categorical predictors.** In particular:

1. Fit multiple regression in Stata 
2. Test model assumptions 
2. Add interactions 
3. Add categorical predictors 
</div>


### Today's Dataset

* We have a dataset (``states.dta``) on a variety of variables for all 50 states
* Variables include population, density, energy use, voting tendencies, graduation rates, income, etc.

* We're going to be predicting **mean composite SAT score** using **education expense**, controlling for **median family income**, and **% of HS graduates taking SAT**
* Does the amount of money spent on education (``expense``) affect the mean SAT score (``csat``) in a state, controlling for family income(``income``) and percentage of students taking SATs (``percent``) in a state?


### Opening Files

* Look at bottom left hand corner of Stata screen
    + This is the directory Stata is currently reading from
* Files are located in the dataSets folder in StataMod
* Start by telling Stata where to look for these

```{stata}
  // change directory
  cd "~/Desktop/Stata/StataMod"
```


* Use dir to see what is in the directory:

```{stata}
  dir
  cd dataSets
```


* Load the data

```{stata}
  // use the states data set
  use dataSets/states.dta
```


### Steps for running OLS regression:

1.  Examine descriptive statistics
2.  Look at relationship graphically and test correlation(s)
3.  Run an initial model 
4.  Test regression assumptions 
5.  Finalize model and interpret results 


#### Preliminaries

* First, let's look at some descriptives 

```{stata}
  // descriptive statistics and correlations
  sum expense income percent csat
  
  pwcorr csat expense income percent
  pwcorr csat expense income percent, sig
```


#### Fit the model 

* regress csat on expense, income, and percent 

```{stata}
  regress csat expense 
  regress csat expense income percent 
```


#### OLS assumptions

* Assumption 1: Specification is appropriate (i.e., no relevant omitted variables)
* Assumption 2: Homoscedasticity (The variance around the regression model is the same for all values of the predictor variable)
* Assumption 3: Multicollinearity 
* Assumption 4: There needs to be linear relationships between variables 
* Assumption 5: Normal Distribution of residuals (errors) 


##### Specification

* The model specification should be informed by theory - i.e., our substantive knowledge of the subject matter. 
* It's important to include all relevant predictors in the model, otherwise our estimates will be biased.


##### Homoscedasticity

* rvfplot(read residual-versus-fitted plot) graphs the residuals against the fitted values 
* In a well-fitted model, there should be no pattern to the residuals plotted against the fitted
  values

```{stata}
  rvfplot
```


##### Multicollinearity

* When the degree of multicollinearity increases, the regression coefficients can be unstable and the standrard error for the correlation get inflated 
* The rule of thumb is that a variable with vif (variance infltion factor) value greater than 10 should be re-examined

```{stata}
vif
```


##### Linearity 

* When we perform a regression analysis, we assume that the relationship between the response variable and the predictors is linear. 

```{stata}
  twoway (scatter csat expense)(lfit csat expense)(lowess csat expense)
```


##### Normality

* A simple histogram of the residuals can be informative

```{stata}
  // graph the residual values of csat
  predict resid, residual
  histogram resid, normal 
```

* Type -help regress postestimation- for more information about these statistical tools. 



### Exercise 0

**Multiple Regression**

Open the datafile, ``gss.dta``

1.  Select a few variables to use in a multiple regression of your own. Before running the regression, examine descriptive of the variables and generate a few scatterplots.

```{stata}
##
```

2.  Run your regression.

```{stata}
##
```

3.  Examine the plausibility of the assumptions of normality and homoscedasticity.

```{stata}
##
```


### Interactions

* open the ``states.dta`` dataset again 
* What if we wanted to test an interaction between percent & high?
* Option 1: generate product terms by hand

```{stata}
  // generate product of percent and high
  gen percenthigh = percent*high 
  regress csat expense income percent high percenthigh
```


* What if we wanted to test an interaction between percent & high?
* Option 2: Let Stata do your dirty work

```{stata}
  // use the # sign to represent interactions 
  regress csat percent high c.percent#c.high
  // same as . regress csat c.percent##high
```


### Categorical Predictors

* For categorical variables, we first need to dummy code
* Use region as example
    + Option 1: create dummy codes before fitting regression model

```{stata}
  // create region dummy codes using tab 
  tab region, gen(region)

  //regress csat on region
  regress csat region1 region2 region3
```


* For categorical variables, we first need to dummy code
* Use region as example
    + Option 2: Let Stata do it for you

```{stata}
  // regress csat on region using fvvarlist syntax
  // see help fvvarlist for details
  regress csat i.region
```


### Exercise 1

**Regression, Categorical Predictors, & Interactions**

Open the datafile ``gss.dta``

1.  Add on to the regression equation that you created in exercise 0 by generating an interaction term and testing the interaction.

```{stata}
##
```

2.  Try adding a categorical variable to your regression (remember, it will need to be dummy coded). You could use any existing or generate a new categorical variable from one of the continuous variables in the dataset.

```{stata}
##
```


## Exporting & saving results

<div class="alert alert-info">
**GOAL: To learn how to store and export Stata models.** In particular:

1. How to store results and compare between models 
2. How to export stata model to Excel 
</div>


### Regression tables

* Store and compare results 
* Stata offers several user-friendly options for storing and viewing regression output from multiple models
* First, download the necessary packages:

```{stata}
  // install outreg2 package
  findit outreg2
```


### Saving & replaying

* You can store regression model results in Stata

```{stata}
  // fit two regression models and store the results
  regress csat expense income percent high
  estimates store Model1
  regress csat expense income percent high i.region
  estimates store Model2
```


* Stored models can be recalled

```{stata}
  // Display Model1
  estimates replay Model1
```


* Stored models can be compared

```{stata}
  // Compare Model1 and Model2 coefficients
  estimates table Model1 Model2
```


### Exporting to Excel

* Avoid human error when transferring coefficients into tables
* Excel can be used to format publication-ready tables

```{stata}
  outreg2 [Model1 Model2] using csatprediction.xls, replace
```



## Obtaining margins of responses 

<div class="alert alert-info">
**GOAL: To learn the basics about margins in Stata** In particular:

1. An example of margins using OLS regression
2. An example of margins using logistic regression 
</div>


### Margins of OLS regression 

* We will be continuing with our previous example: predict ``csat`` using ``expense`` and another factor variable ``region``, controlling for ``income`` and ``percent``, using the ``states.dta`` data set. 


#### Load the data

```{stata}
  // use the states data set
  use dataSets/states.dta
```


#### Fit the model 

* regress csat on expense, income, percent, and region 

```{stata}
  regress csat expense income percent i.region 
```


#### Obtain average values of y 

```{stata}
  margins region
```


#### Obtain average values at the mean of the covariates 

```{stata}
  margins region, atmeans
```


#### Margins with continuous variables 

* margins requires more guidance with continuous covariates 

```{stata}
//doing this will produce an error 
margins expense
//using the at() option 
margins, at (expense=5000)
```

* If you want to obtain margins in increments 

```{stata}
margins, at(expense=(2000(1000)8000))

```



### Margins of logistic regression 

* Using the ``gss.dta`` data set, we're going to be predicting **general happiness** using **highest education degree**, controlling for **sex**, **age**, and **race**
* Does one's highest education degree (``degree``) affect their general happiness (``happy1``), controlling for sex (``sex``), age (``age``), and one's marital status (``marital``)?


### Dataset

* We will load the data 

```{stata}
  // use the gss data set
  use dataSets/gss.dta
```


### Steps in fitting a logistic regression model and examine the predicted probabilities 

1. Run summary statistics for outcome variable and independent variables 
2. Run the model to obtain log odds/odds ratio 
3. Examine overall effect of a variable 
4. Get predicted probabilities using margins  
5. Examine model fit and compare models 


#### Run summary statistics 

* Run summary statistics for continuous variables 

```{stata}
summarize age degree 

```

* Run summary statistics for categorical variables 

```{stata}
tab sex marital 

```


#### Run the model 

* run logit regression 

```{stata}
logit happy1 i.sex age i.marital i.degree
logit happy1 i.sex age i.marital i.degree, or 
```


#### Test overall effect of a predictor 

* We can test for an overall effect of degree using the test command. Below we see that the overall effect of degree is statistically significant.

```{stata}
test 1.degree 2.degree 3.degree 4.degree 

```


#### Get predicted probabilities using the margins command 

* Fit all other covariates at the mean 

```{stata}
margins degree, atmeans 

```

* Below we generate the predicted probabilities for age from 20 to 80 in increments of 10. 

* Because we have not specified either atmeans or used at(.) to specify values at with the other predictor variables are held, the values in the table are average predicted probabilities calculated using the sample values of the other predictor variables.

```{stata}
margins , at(age=(20(10)80))  vsquish
```


#### Test model fit 

* We may also wish to see measures of how well our model fits. This can be particularly useful when comparing competing models. The user-written command fitstat produces a variety of fit statistics. You can find more information on fitstat by typing -search fitstat-.  

```{stata}
fitstat

```


### Exercise 2

**Margins**

Open the datafile ``gss.dta``

1. Based on the previous model you specified in Exercise 1, obtain predicted margins of a categorical predictor, fixing all other covariates at the mean 

```{stata}
##
```

2. Obtain predicted margins of a continuous predictor at a certain value 

```{stata}
##
```

3. Obtain fit statistics for your model 

```{stata}
##
```


## Different types of adjusted predictions and marginal effects 

<div class="alert alert-info">
**GOAL: To learn the three most common types of adjusted predictions in Stata, and how to calculate the corresponding marginal effects, using a case example** In particular:

1. **APMs** (adjusted predictions at the mean) and **MEM** (marginal effects at the mean) 
2. **AAPs** (average adjusted predictions) and **AME** (average marginal effects)
3. **APRs** (adjusted predictions at representative values) and **MER** (marginal effects at representative values).
</div>


### Opening the data set 

* The case study examples use the Second National Health and Nutrition Examination Survey (NHANES II) which was conducted in the mid to late 1970s. 
* The examples were drawn from online materials from Prof. Richard Williams from https://www3.nd.edu/~rwilliam/stats/Margins01.pdf
* Stata provides online access to an adultsonly extract from these data.
* More on the study can be found at https://wwwn.cdc.gov/nchs/nhanes/nhanes2/


#### Fit the basic model 

```{stata}
logit diabetes black female age, nolog 

```


#### Marginal effects at the mean(MEM)

```{stata}
//obtain APM for Black and White
margins black feamle, atmeans

//calculate MEM, meaning having the mean value for the other independent variables in the model 
margins, dydx(black female) atmeans
```


#### Average marginal effects (AME)

```{stata}
//obtain AAPs 
margins black female 

//compute the average of all the marginal effects 
margins, dydx(black female)

```


#### Marginal effects at representative values (MER)

```{stata}
//choose range of values for one or more variable
margins black, at(age=(20 30 40 50 60 70)) vsquish 

//see how the marginal effects differ across that range 
margins, dydx(black female) at(age=(20 30 40 50 60 70)) vsquish 
```


#### Graphing results 

```{stata}
marginsplot
```


### Exercise 3

**Choose the appropriate margins**

Open the data set ``gss.dta``

1. Based on the previous model you specified in Exercise 3, choose a variable you are interested, obtain marginal effect at the mean (MEM)

```{stata}
##
```

2. Obtain average marginal effect (AME)

```{stata}
##
```

3. Obtain marginal effects at representative values (MER) 

```{stata}
##
```



## Wrap-up

### Feedback

These workshops are a work in progress, please provide any feedback to: help@iq.harvard.edu

### Resources

* IQSS 
    + Workshops: <https://dss.iq.harvard.edu/workshop-materials>
    + Data Science Services: <https://dss.iq.harvard.edu/>
    + Research Computing Environment: <https://iqss.github.io/dss-rce/>

* HBS
    + Research Computing Services workshops: <https://training.rcs.hbs.org/workshops>
    + Other HBS RCS resources: <https://training.rcs.hbs.org/workshop-materials>
    + RCS consulting email: <mailto:research@hbs.edu>

* Stata
    + UCLA website: <http://www.ats.ucla.edu/stat/Stata/>
    + Stata website: <http://www.stata.com/help.cgi?contents>
    + Email list: <http://www.stata.com/statalist/>
    



